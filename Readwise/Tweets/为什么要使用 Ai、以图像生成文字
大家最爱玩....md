# 为什么要使用 Ai、以图像生成文字
大家最爱玩...

![rw-book-cover](https://pbs.twimg.com/profile_images/1615204555/bg_green_300x300.jpg)

## Metadata
- Author: [[@nishuang on Twitter]]
- Full Title: 为什么要使用 Ai、以图像生成文字
大家最爱玩...
- Category: #tweets
- URL: https://twitter.com/nishuang/status/1643040077977624577

## Highlights
- 为什么要使用 AI、以图像生成文字
  大家最爱玩的不是 Midjourney 们以文字生成图像么
  今天我测试了高产的 Jina 团队的又一个新 AI 工具 Scenex：你给它一张图片，它用自然语言描述这张图片里有什么内容、解释这些内容代表了什么
  https://t.co/yp7E4t3o3d
  测试之前我就自行脑补这个功能的使用场景：… https://t.co/5jm26conY1 
  ![](https://pbs.twimg.com/media/Fs1ACKHWIAAgU5n.jpg) ([View Tweet](https://twitter.com/nishuang/status/1643040077977624577))
- 注：前面说的 2B 指“对公”，不是“二逼”
  2）识别图片中信息的能力
  按照 Scenex 的产品介绍，它用了高级 AI 模型来识别图像里的内容…从用户角度来测试“高级 AI 模型”，最简单的方法是让它分析似是而非、很多“噪音”的图片… https://t.co/dwxwIfPt4V 
  ![](https://pbs.twimg.com/media/Fs1Cd2sX0AEUyq4.jpg) 
  ![](https://pbs.twimg.com/media/Fs1ChEuXoAAg_VR.jpg) ([View Tweet](https://twitter.com/nishuang/status/1643042842929946624))
- 接着试试 Scenex 识别其他类型图片的能力
  我测试了新闻照片、动物/宠物照片、漫画、APP UI 等不同类别的图片
  能认识马斯克和电动汽车，也能识别猫和狗
  识别 UI 相对困难，准确度差一点，不过它识别出了这是 iPhone 界面、播放器界面、视频和音频界面，其实很不错了… https://t.co/5yrwDoQRWK 
  ![](https://pbs.twimg.com/media/Fs1GjvdWAAYuaTd.jpg) 
  ![](https://pbs.twimg.com/media/Fs1GmAoWcAEPjVN.jpg) 
  ![](https://pbs.twimg.com/media/Fs1Gh2PWAAY_xXp.jpg) 
  ![](https://pbs.twimg.com/media/Fs1GfzLWcAA29Ig.jpg) ([View Tweet](https://twitter.com/nishuang/status/1643047124865622016))
- 3）用自然语言描述已识别信息的能力
  以 Scenex 官网模糊的介绍和我自己的理解，Scenex 应该是在 AI 的图像识别模型之上，又增加了一层类似 ChatGPT 的 LLM 模型来描述识别出来的信息
  ChatGPT 大家都懂，它非常善于在不懂的前提下把事情说得非常漂亮
  还是以之前的几张测试图片来解释，点图片上的… https://t.co/yudbzE8ZHP 
  ![](https://pbs.twimg.com/media/Fs1ZjTsWcAASd9r.jpg) 
  ![](https://pbs.twimg.com/media/Fs1ZlmYWAAAkxAv.jpg) 
  ![](https://pbs.twimg.com/media/Fs1Zp0OXgAI_z_X.jpg) 
  ![](https://pbs.twimg.com/media/Fs1ZntHWwAMGEUT.jpg) ([View Tweet](https://twitter.com/nishuang/status/1643069087600332800))
- 回到我最初的问题，那为什么要使用 AI、以图像生成文字呢？
  SceneXplain 官网对产品使用场景的定义，是 storytelling，也就是用文字去帮助图像表达更多信息… https://t.co/eLKWPZvr3r ([View Tweet](https://twitter.com/nishuang/status/1643074446968737794))
- 另外很巧合的是，之前我泛泛一说“最 cutting edge 的想法，先用它来描述图片，再拿描述语训练 Midjourney 的提示语，用一个 AI 哺育另一个 AI”…
  今天成为了现实，实现者就是 Midjourney 自己
  今天他们推出了一个 /describe 功能：你上传一张图片，Midjourney… https://t.co/noymvBWZkY 
  ![](https://pbs.twimg.com/media/Fs1gxLDWIAAL2n2.png) 
  ![](https://pbs.twimg.com/media/Fs1gxLJWwAUkWhg.png) ([View Tweet](https://twitter.com/nishuang/status/1643076642644848641))
- 拿 SceneXplain 识别图像得到了通用的文字描述，去当做 Midjourney 那种专用系统的专用指令，效果肯定会很糟糕，双方的标准不同，强行互通的结果跟谢耳朵玩“你画我猜”一样不可描述
  不过在识别图像得到文字描述后，倒是可以利用 ChatGPT 之类的 AI… https://t.co/ptYFtLLFtc 
  ![](https://pbs.twimg.com/media/Fs1i81HXwAMEg_W.jpg) ([View Tweet](https://twitter.com/nishuang/status/1643079205758828546))
